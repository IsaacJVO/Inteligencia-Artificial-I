{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc54c664",
   "metadata": {},
   "source": [
    "# Trabajo de Aprendizaje No Supervisado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a195b4",
   "metadata": {},
   "source": [
    "## Punto 2\n",
    "\n",
    "- Buscar un **dataset sin etiquetas** que cumpla las siguientes condiciones:\n",
    "  - Número de variables (**n**) mayor a **10**  \n",
    "  - Número de ejemplos (**m**) mayor a **10.000**\n",
    "- Los datasets que incluyan **contenido gráfico, de audio, texto o datos con efectos reales en cualquier ámbito** tendrán **mayor puntuación**.  \n",
    "- Los **datasets no deben ser similares**, por lo que se debe **coordinar con el universitario Romero Morales Jhojan Erick**.\n",
    "- Aplicar las siguientes técnicas:\n",
    "  - **Aprendizaje semisupervisado**\n",
    "  - **Aprendizaje activo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c557e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: (7796, 618)\n",
      "Características (X): (7796, 617)\n",
      "Etiquetas (y): (7796,)\n",
      "Número de variables: 617\n",
      "Número de ejemplos: 7796\n",
      "Número de clases únicas: 26\n",
      "Rango de etiquetas: 0 - 25\n"
     ]
    }
   ],
   "source": [
    "# Punto 2: Aprendizaje Semisupervisado y Aprendizaje Activo\n",
    "# Dataset: ISOLET - Reconocimiento de letras del abecedario por características de audio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar el dataset ISOLET\n",
    "isolet_data = pd.read_csv(\"../Dataset/ISOLET (2).csv\")\n",
    "print(f\"Dataset cargado: {isolet_data.shape}\")\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = isolet_data.iloc[:, :-1].values  \n",
    "y = isolet_data.iloc[:, -1].values   \n",
    "\n",
    "# Convertir etiquetas de string a números si es necesario\n",
    "if isinstance(y[0], str):\n",
    "    unique_labels = np.unique(y)\n",
    "    label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "    y = np.array([label_map[label] for label in y])\n",
    "\n",
    "print(f\"Características (X): {X.shape}\")\n",
    "print(f\"Etiquetas (y): {y.shape}\")\n",
    "print(f\"Número de variables: {X.shape[1]}\")\n",
    "print(f\"Número de ejemplos: {X.shape[0]}\")\n",
    "print(f\"Número de clases únicas: {len(np.unique(y))}\")\n",
    "print(f\"Rango de etiquetas: {min(y)} - {max(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9706553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento - X: (5847, 617), y: (5847,)\n",
      "Prueba - X: (1949, 617), y: (1949,)\n",
      "\n",
      "Distribución de letras en entrenamiento:\n",
      "  A (clase 0): 229 ejemplos\n",
      "  B (clase 1): 225 ejemplos\n",
      "  C (clase 2): 227 ejemplos\n",
      "  D (clase 3): 206 ejemplos\n",
      "  E (clase 4): 229 ejemplos\n",
      "  F (clase 5): 231 ejemplos\n",
      "  G (clase 6): 205 ejemplos\n",
      "  H (clase 7): 229 ejemplos\n",
      "  I (clase 8): 223 ejemplos\n",
      "  J (clase 9): 236 ejemplos\n",
      "  K (clase 10): 230 ejemplos\n",
      "  L (clase 11): 225 ejemplos\n",
      "  M (clase 12): 219 ejemplos\n",
      "  N (clase 13): 231 ejemplos\n",
      "  O (clase 14): 241 ejemplos\n",
      "  P (clase 15): 227 ejemplos\n",
      "  Q (clase 16): 223 ejemplos\n",
      "  R (clase 17): 237 ejemplos\n",
      "  S (clase 18): 216 ejemplos\n",
      "  T (clase 19): 232 ejemplos\n",
      "  U (clase 20): 216 ejemplos\n",
      "  V (clase 21): 217 ejemplos\n",
      "  W (clase 22): 215 ejemplos\n",
      "  X (clase 23): 232 ejemplos\n",
      "  Y (clase 24): 222 ejemplos\n",
      "  Z (clase 25): 224 ejemplos\n"
     ]
    }
   ],
   "source": [
    "# Preparar el dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(f\"Entrenamiento - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Prueba - X: {X_test.shape}, y: {y_test.shape}\")\n",
    "\n",
    "# Mostrar distribución de clases\n",
    "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\nDistribución de letras en entrenamiento:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    letter = chr(ord('A') + label) if label <= 25 else f\"Clase_{label}\"\n",
    "    print(f\"  {letter} (clase {label}): {count} ejemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b803c7",
   "metadata": {},
   "source": [
    "## Aprendizaje Semisupervisado\n",
    "\n",
    "Aplicaremos K-Means para seleccionar muestras representativas y luego entrenar un modelo con pocas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0180999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clusters K-Means: 26\n",
      "Shape de distancias: (5847, 26)\n",
      "Shape de distancias: (5847, 26)\n"
     ]
    }
   ],
   "source": [
    "# Aplicar K-Means para encontrar muestras representativas\n",
    "k = len(np.unique(y_train))  \n",
    "print(f\"Número de clusters K-Means: {k}\")\n",
    "\n",
    "# Aplicar K-Means\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "X_audio_dist = kmeans.fit_transform(X_train)\n",
    "\n",
    "print(f\"Shape de distancias: {X_audio_dist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1dcec048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de muestras representativas: (26, 617)\n",
      "Se seleccionaron 26 muestras representativas\n",
      "\n",
      "Muestras representativas seleccionadas:\n",
      "  Cluster 1: Muestra 5303 → Letra Y (clase 24)\n",
      "  Cluster 2: Muestra 1060 → Letra U (clase 20)\n",
      "  Cluster 3: Muestra 2387 → Letra Z (clase 25)\n",
      "  Cluster 4: Muestra 3327 → Letra R (clase 17)\n",
      "  Cluster 5: Muestra 5796 → Letra W (clase 22)\n",
      "  Cluster 6: Muestra 536 → Letra P (clase 15)\n",
      "  Cluster 7: Muestra 4495 → Letra C (clase 2)\n",
      "  Cluster 8: Muestra 216 → Letra T (clase 19)\n",
      "  Cluster 9: Muestra 1956 → Letra U (clase 20)\n",
      "  Cluster 10: Muestra 1254 → Letra J (clase 9)\n",
      "  Cluster 11: Muestra 2365 → Letra E (clase 4)\n",
      "  Cluster 12: Muestra 297 → Letra N (clase 13)\n",
      "  Cluster 13: Muestra 3645 → Letra I (clase 8)\n",
      "  Cluster 14: Muestra 3900 → Letra F (clase 5)\n",
      "  Cluster 15: Muestra 4697 → Letra X (clase 23)\n",
      "  Cluster 16: Muestra 2348 → Letra T (clase 19)\n",
      "  Cluster 17: Muestra 1889 → Letra W (clase 22)\n",
      "  Cluster 18: Muestra 439 → Letra B (clase 1)\n",
      "  Cluster 19: Muestra 162 → Letra C (clase 2)\n",
      "  Cluster 20: Muestra 4035 → Letra Z (clase 25)\n",
      "  Cluster 21: Muestra 5207 → Letra G (clase 6)\n",
      "  Cluster 22: Muestra 2016 → Letra P (clase 15)\n",
      "  Cluster 23: Muestra 136 → Letra D (clase 3)\n",
      "  Cluster 24: Muestra 2067 → Letra H (clase 7)\n",
      "  Cluster 25: Muestra 3289 → Letra W (clase 22)\n",
      "  Cluster 26: Muestra 3099 → Letra R (clase 17)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar muestras representativas\n",
    "idxs = np.argmin(X_audio_dist, axis=0)  \n",
    "X_representative_audio = X_train[idxs]  \n",
    "\n",
    "print(f\"Shape de muestras representativas: {X_representative_audio.shape}\")\n",
    "print(f\"Se seleccionaron {len(idxs)} muestras representativas\")\n",
    "\n",
    "# Obtener las etiquetas reales de las muestras representativas\n",
    "y_representative_audio = y_train[idxs]\n",
    "\n",
    "print(\"\\nMuestras representativas seleccionadas:\")\n",
    "for i, (idx, label) in enumerate(zip(idxs, y_representative_audio)):\n",
    "    letter = chr(ord('A') + label) if label <= 25 else f\"Clase_{label}\"\n",
    "    print(f\"  Cluster {i+1}: Muestra {idx} → Letra {letter} (clase {label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "675c713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión usando solo 26 muestras representativas: 0.5162 = 51.62%\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo con muestras representativas\n",
    "log_reg_representative = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg_representative.fit(X_representative_audio, y_representative_audio)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_representative = log_reg_representative.score(X_test, y_test)\n",
    "print(f\"Precisión usando solo {k} muestras representativas: {accuracy_representative:.4f} = {accuracy_representative * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8acff590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión usando 26 muestras aleatorias: 0.40 = 39.82%\n",
      "Mejora del aprendizaje semisupervisado: +0.12 = +11.80%\n"
     ]
    }
   ],
   "source": [
    "# Comparación con modelo aleatorio\n",
    "n_representative = len(X_representative_audio)\n",
    "log_reg_random = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg_random.fit(X_train[:n_representative], y_train[:n_representative])\n",
    "\n",
    "# Evaluar modelo aleatorio\n",
    "accuracy_random = log_reg_random.score(X_test, y_test)\n",
    "print(f\"Precisión usando {n_representative} muestras aleatorias: {accuracy_random:.2f} = {accuracy_random * 100:.2f}%\")\n",
    "\n",
    "# Mostrar la diferencia\n",
    "improvement = accuracy_representative - accuracy_random\n",
    "print(f\"Mejora del aprendizaje semisupervisado: {improvement:+.2f} = {improvement * 100:+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12ee7ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas propagadas a 5847 muestras\n",
      "Precisión con 1000 muestras semi-etiquetadas: 0.5428\n"
     ]
    }
   ],
   "source": [
    "# Propagación de etiquetas\n",
    "y_train_propagated = np.empty(len(X_train))\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_ == i] = y_representative_audio[i]\n",
    "\n",
    "print(f\"Etiquetas propagadas a {len(y_train_propagated)} muestras\")\n",
    "\n",
    "# Entrenar con las etiquetas propagadas\n",
    "log_reg_propagated = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "n_semisupervised = 1000\n",
    "log_reg_propagated.fit(X_train[:n_semisupervised], y_train_propagated[:n_semisupervised])\n",
    "\n",
    "# Evaluar modelo con propagación\n",
    "accuracy_propagated = log_reg_propagated.score(X_test, y_test)\n",
    "print(f\"Precisión con {n_semisupervised} muestras semi-etiquetadas: {accuracy_propagated:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e2c57",
   "metadata": {},
   "source": [
    "## Aprendizaje Activo\n",
    "\n",
    "Identificaremos las muestras más inciertas para el modelo y las usaremos para mejorar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79c5bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades calculadas para 1000 muestras\n",
      "Rango de confianzas: 0.734 \n"
     ]
    }
   ],
   "source": [
    "# Calcular probabilidades de predicción para aprendizaje activo\n",
    "n_active_samples = 1000\n",
    "probas = log_reg_propagated.predict_proba(X_train[:n_active_samples])\n",
    "\n",
    "# Obtener el índice de la clase más probable para cada muestra\n",
    "labels_ixs = np.argmax(probas, axis=1)\n",
    "\n",
    "# Obtener la confianza (probabilidad máxima) de cada predicción\n",
    "confidences = probas[np.arange(len(probas)), labels_ixs]\n",
    "\n",
    "print(f\"Probabilidades calculadas para {n_active_samples} muestras\")\n",
    "print(f\"Rango de confianzas: {confidences.min():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aadb6505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleccionadas las 50 muestras más inciertas\n",
      "Las 10 muestras con menor confianza:\n",
      "  Muestra 337: Confianza=0.734 → Letra O (clase 14)\n",
      "  Muestra 480: Confianza=0.751 → Letra M (clase 12)\n",
      "  Muestra 986: Confianza=0.766 → Letra C (clase 2)\n",
      "  Muestra 195: Confianza=0.798 → Letra M (clase 12)\n",
      "  Muestra 176: Confianza=0.802 → Letra D (clase 3)\n",
      "  Muestra 34: Confianza=0.804 → Letra M (clase 12)\n",
      "  Muestra 294: Confianza=0.807 → Letra S (clase 18)\n",
      "  Muestra 984: Confianza=0.807 → Letra C (clase 2)\n",
      "  Muestra 249: Confianza=0.807 → Letra O (clase 14)\n",
      "  Muestra 78: Confianza=0.819 → Letra H (clase 7)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar muestras más inciertas\n",
    "sorted_ixs = np.argsort(confidences)\n",
    "\n",
    "k_active = 50  # cantidad de muestras inciertas a revisar\n",
    "\n",
    "# Obtener las muestras más inciertas\n",
    "X_most_uncertain = X_train[:n_active_samples][sorted_ixs[:k_active]]\n",
    "y_most_uncertain = y_train[:n_active_samples][sorted_ixs[:k_active]]\n",
    "\n",
    "print(f\"Seleccionadas las {k_active} muestras más inciertas\")\n",
    "print(\"Las 10 muestras con menor confianza:\")\n",
    "for i in range(min(10, k_active)):\n",
    "    idx = sorted_ixs[i]\n",
    "    confidence = confidences[idx]\n",
    "    true_label = y_train[:n_active_samples][idx]\n",
    "    letter = chr(ord('A') + true_label) if true_label <= 25 else f\"Clase_{true_label}\"\n",
    "    print(f\"  Muestra {idx}: Confianza={confidence:.3f} → Letra {letter} (clase {true_label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bbc77ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión usando aprendizaje activo (50 muestras inciertas): 0.3197\n"
     ]
    }
   ],
   "source": [
    "# Entrenar con aprendizaje activo\n",
    "log_reg_active = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "\n",
    "# Entrenar con las muestras más inciertas\n",
    "log_reg_active.fit(X_most_uncertain, y_most_uncertain)\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "accuracy_active = log_reg_active.score(X_test, y_test)\n",
    "print(f\"Precisión usando aprendizaje activo ({k_active} muestras inciertas): {accuracy_active:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
